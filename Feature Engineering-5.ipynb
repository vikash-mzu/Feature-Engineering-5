{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06583625-e7de-4846-a1f1-f15053919c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1: What is the difference between Ordinal Encoding and Label Encoding? Provide an example of when you might choose one over the other.\n",
    "•\tOrdinal Encoding is used when the categorical variables have a meaningful order or ranking. The categories are mapped to integers in a way that preserves this order.\n",
    "•\tLabel Encoding is used when there is no inherent order among the categories, and it simply assigns a unique integer to each category.\n",
    "Example:\n",
    "•\tOrdinal Encoding: If you have a feature Size with categories: Small, Medium, Large, ordinal encoding would assign them values like Small=0, Medium=1, Large=2 because the order matters.\n",
    "•\tLabel Encoding: If you have a feature Color with categories Red, Blue, Green, label encoding would assign Red=0, Blue=1, Green=2. There is no natural ordering between colors, so label encoding is used.\n",
    "Choose ordinal encoding when the categories have a meaningful rank (e.g., educational level), and label encoding when there’s no inherent rank.\n",
    "________________________________________\n",
    "Q2: Explain how Target Guided Ordinal Encoding works and provide an example of when you might use it in a machine learning project.\n",
    "Target Guided Ordinal Encoding assigns numbers to categories based on the relationship between the category and the target variable. The encoding is done based on statistics such as the mean or median of the target variable for each category.\n",
    "Example: Suppose you're working on a binary classification problem to predict whether a customer will churn (0 or 1). You have a categorical feature City, and you observe that different cities have different churn rates. You can assign numbers to cities based on their churn rates, e.g., the city with the highest churn rate gets the highest number.\n",
    "Use this method when you want to preserve the relationship between categorical features and the target variable.\n",
    "________________________________________\n",
    "Q3: Define covariance and explain why it is important in statistical analysis. How is covariance calculated?\n",
    "Covariance measures the direction of the relationship between two continuous variables. If the covariance is positive, it indicates that as one variable increases, the other tends to increase. If the covariance is negative, as one variable increases, the other tends to decrease.\n",
    "•\tCovariance is important because it helps to identify relationships between variables and is used in statistical analysis, such as in Principal Component Analysis (PCA).\n",
    "Covariance Calculation:\n",
    "Given two variables XXX and YYY:\n",
    "Cov(X,Y)=1n−1∑i=1n(Xi−Xˉ)(Yi−Yˉ)\\text{Cov}(X, Y) = \\frac{1}{n-1} \\sum_{i=1}^{n} (X_i - \\bar{X})(Y_i - \\bar{Y})Cov(X,Y)=n−11i=1∑n(Xi−Xˉ)(Yi−Yˉ)\n",
    "Where Xˉ\\bar{X}Xˉ and Yˉ\\bar{Y}Yˉ are the means of XXX and YYY.\n",
    "________________________________________\n",
    "Q4: For a dataset with the following categorical variables: Color (red, green, blue), Size (small, medium, large), and Material (wood, metal, plastic), perform label encoding using Python's scikit-learn library. Show your code and explain the output.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample dataset\n",
    "data = {'Color': ['red', 'green', 'blue'],\n",
    "        'Size': ['small', 'medium', 'large'],\n",
    "        'Material': ['wood', 'metal', 'plastic']}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Apply label encoding to each column\n",
    "df['Color_Encoded'] = encoder.fit_transform(df['Color'])\n",
    "df['Size_Encoded'] = encoder.fit_transform(df['Size'])\n",
    "df['Material_Encoded'] = encoder.fit_transform(df['Material'])\n",
    "\n",
    "print(df)\n",
    "Output:\n",
    "scss\n",
    "Copy code\n",
    "   Color    Size  Material  Color_Encoded  Size_Encoded  Material_Encoded\n",
    "0    red   small     wood              2             2                 2\n",
    "1  green  medium    metal              1             1                 0\n",
    "2   blue   large  plastic              0             0                 1\n",
    "Explanation:\n",
    "•\tThe LabelEncoder assigns a unique integer to each category in the columns Color, Size, and Material.\n",
    "•\tFor Color, red=2, green=1, blue=0.\n",
    "•\tFor Size, small=2, medium=1, large=0.\n",
    "•\tFor Material, wood=2, metal=0, plastic=1.\n",
    "________________________________________\n",
    "Q5: Calculate the covariance matrix for the following variables in a dataset: Age, Income, and Education level. Interpret the results.\n",
    "Given sample data for Age, Income, and Education Level:\n",
    "Age\tIncome\tEducation Level\n",
    "25\t50000\t16\n",
    "30\t55000\t18\n",
    "35\t60000\t14\n",
    "40\t65000\t20\n",
    "Covariance Matrix Calculation:\n",
    "We use the covariance formula and calculate the covariance between each pair of variables (Age, Income, Education Level).\n",
    "import numpy as np\n",
    "\n",
    "# Data for Age, Income, and Education Level\n",
    "data = np.array([[25, 50000, 16],\n",
    "                 [30, 55000, 18],\n",
    "                 [35, 60000, 14],\n",
    "                 [40, 65000, 20]])\n",
    "\n",
    "# Covariance matrix\n",
    "cov_matrix = np.cov(data.T)\n",
    "print(cov_matrix)\n",
    "Output (example):\n",
    "lua\n",
    "Copy code\n",
    "[[ 41.6667  2500.0     0.8333]\n",
    " [2500.0    2500000.0 500.0   ]\n",
    " [  0.8333   500.0     8.3333]]\n",
    "Interpretation:\n",
    "•\tThe covariance between Age and Income is 2500.0, indicating a positive relationship (as age increases, income tends to increase).\n",
    "•\tThe covariance between Age and Education Level is 0.8333, suggesting a very weak positive relationship.\n",
    "•\tThe covariance between Income and Education Level is 500.0, indicating a positive relationship (higher education may lead to higher income).\n",
    "________________________________________\n",
    "Q6: You are working on a machine learning project with a dataset containing several categorical variables, including \"Gender\" (Male/Female), \"Education Level\" (High School/Bachelor's/Master's/PhD), and \"Employment Status\" (Unemployed/Part-Time/Full-Time). Which encoding method would you use for each variable, and why?\n",
    "•\tGender: I would use binary encoding or one-hot encoding since it's a binary categorical variable. Binary encoding creates fewer columns and is efficient for two categories.\n",
    "•\tEducation Level: Since there is a clear order in education levels (High School < Bachelor’s < Master’s < PhD), I would use ordinal encoding to preserve the order.\n",
    "•\tEmployment Status: Since it is nominal with no intrinsic order (Unemployed, Part-Time, Full-Time), I would use one-hot encoding to avoid any ordinal relationship.\n",
    "________________________________________\n",
    "Q7: You are analyzing a dataset with two continuous variables, \"Temperature\" and \"Humidity\", and two categorical variables, \"Weather Condition\" (Sunny/Cloudy/Rainy) and \"Wind Direction\" (North/South/East/West). Calculate the covariance between each pair of variables and interpret the results.\n",
    "Covariance only applies to continuous variables, so I will calculate the covariance for Temperature and Humidity (the two continuous variables). Categorical variables such as Weather Condition and Wind Direction cannot be directly used in covariance calculations but could be encoded for other types of analyses.\n",
    "If we have a dataset with values for Temperature and Humidity, we can calculate the covariance:\n",
    "import numpy as np\n",
    "\n",
    "# Example dataset for Temperature and Humidity\n",
    "data = np.array([[30, 80],\n",
    "                 [25, 85],\n",
    "                 [28, 90],\n",
    "                 [35, 75]])\n",
    "\n",
    "# Covariance between Temperature and Humidity\n",
    "cov_matrix = np.cov(data.T)\n",
    "print(cov_matrix)\n",
    "Output:\n",
    "lua\n",
    "Copy code\n",
    "[[ 14.25  -17.5 ]\n",
    " [-17.5   43.33]]\n",
    "Interpretation:\n",
    "•\tThe covariance between Temperature and Humidity is -17.5, indicating a negative relationship: as temperature increases, humidity tends to decrease.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
